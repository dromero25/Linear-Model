---
title: "Linear Model"
author: "Demian Romero"
date: "October 23, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
mydata = read.csv ('Raw Data.csv')
```

# First Model:SIMS is a function of arm strength

```{r}
model1 = lm(SIMS~ARM, data = mydata)
summary (model1)
```
predict SIMS for ARM = 88

```{r}
x = data.frame (GRIP=94, ARM=88)
predSIMS1 = predict.lm(model1, x)
print (predSIMS1)
```
Prediction interval
```{r}
predict(model1, x, interval = "predict", level = 0.95)
```


# Second Model SIMS is a function of GRIP
```{r}
model2 = lm(SIMS~GRIP, data=mydata)
summary(model2)
```

predict SIMS for GRIP = 94

```{r}
predSIMS2 = predict.lm(model2, x)
print (predSIMS2)

```
Prediction Interval
```{r}
predict(model2, x, interval = "predict")
```



# Third Model SIMS is a function of GRIP + ARM

```{r}
model3 = lm(SIMS~GRIP+ARM, data=mydata)
summary(model3)
```

Predict SIMS for GRIP = 94 and ARM = 88

```{r}
predictSIMS3 = predict.lm(model3, x)
print(predictSIMS3)
```

Prediction Interval
```{r}
predict(model3, x, interval = "predict")
```

Comparison between models 1 and 3
```{r}
anova(model1, model3)
```

$H_0$ There is no difference between the models  

$H_A$ There is a  difference between the models

Since the P-value 4.99e-06 is less than .05 we can reject the null hypothesis and accept the alternative. There is a difference between Model 1 and Model 3. The Residual Signs of Squares is lower on Model 3 than on Model 1 so we can tell Model 3 is a better fit than Model 1. 